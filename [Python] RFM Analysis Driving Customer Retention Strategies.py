# -*- coding: utf-8 -*-
"""[Python] RFM Analysis: Driving Customer Retention Strategies

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lgJpsxZ8LpVFTINeEYS2ADleICn_iHQL

# **IMPORT DATA**
"""

import pandas as pd
ecommerce_retail = pd.read_csv('ecommerce retail.csv')

"""# **PART 1. EDA**

## **1.1. Descriptive Statistic**
"""

ecommerce_retail.head()

# Detect the data type of each column.
ecommerce_retail.info()

"""Comments:
- There are columns with incorrect data types (object) that need to be converted to the correct format.
- There are missing values in the Description and CustomerID columns.
"""

# detect data value
ecommerce_retail.describe()

"""Comments:
- There are instances where Quantity and unitPrice are less than 0 -> check the reasons for this.
- Max value > 75th percentile + 1.5*(75th - 25th percentile) ->  indicating the presence of upper outliers.
"""

# Explore dataset
!pip install ydata-profiling
from ydata_profiling import ProfileReport

profile = ProfileReport(ecommerce_retail)
profile

# Check data category data types (stockcode)
ecommerce_retail['StockCode'].value_counts()

# Check data category data types (Description)
descriptioncheck = ecommerce_retail['Description'].value_counts()
descriptioncheck

descriptioncheck.to_csv('descriptioncheck.csv')

"""After checking the descriptioncheck.csv file, we found that the erroneous orders are those that are noted in lowercase (not capitalized like other descriptions) or contain special characters. Mark those rows as True in a new column labeled "Error."
"""

descriptioncheck_update = pd.read_csv('descriptioncheck.csv')

# Add the 'Error' column: True if there are any lowercase letters or if it only contains '?'
descriptioncheck_update['Error'] = descriptioncheck_update['Description'].str.contains(r'[a-z]|\?', regex=True)
descriptioncheck_update

ecommerce_retail_update = ecommerce_retail.merge(descriptioncheck_update[['Description', 'Error']], on='Description', how='left')
print(ecommerce_retail_update[ecommerce_retail_update['Error'] == True].shape)
print(ecommerce_retail_update.shape)

# Check reason why quantity < 0
ecommerce_retail_update[ecommerce_retail_update['Quantity'] < 0]

# Is Quantity < 0 due to being canceled?
ecommerce_retail_update['InvoiceNo'] = ecommerce_retail_update['InvoiceNo'].astype('string')
ecommerce_retail_update[ecommerce_retail_update['InvoiceNo'].str.startswith('C') & (ecommerce_retail_update['Quantity'] < 0)]

ecommerce_retail_update[~ecommerce_retail_update['InvoiceNo'].str.startswith('C') & (ecommerce_retail_update['Quantity'] < 0)]

"""Comment: 90% of the rows with quantity < 0 are due to cancellations, but there are still 10% of cases where quantity < 0 and UnitPrice = 0 (primarily due to loss or damage).



"""

# Check the reason why Unit Price <0
ecommerce_retail_update[ecommerce_retail_update['UnitPrice'] < 0]

"""Comment: There are 2 cases where Unit Price < 0 described as adjustments for bad debt.

## **1.2. Check data types**
"""

# check data types
ecommerce_retail_update.dtypes

# Corrects data types
ecommerce_retail_update['InvoiceNo'] = ecommerce_retail_update['InvoiceNo'].astype('string')
ecommerce_retail_update['StockCode'] = ecommerce_retail_update['StockCode'].astype('string')
ecommerce_retail_update['Description'] = ecommerce_retail_update['Description'].astype('string')
ecommerce_retail_update['InvoiceDate'] = pd.to_datetime(ecommerce_retail_update['InvoiceDate'])
ecommerce_retail_update['CustomerID'] = ecommerce_retail_update['CustomerID'].astype('string')
ecommerce_retail_update['Country'] = ecommerce_retail_update['Country'].astype('string')
ecommerce_retail_update.dtypes

"""## **1.3. Handling incorrect values**

Action:
- Remove orders with Quantity <0
- Remove orders with UnitPrice <0
- Remove canceled orders
"""

# Only accept orders with Quantity >0
ecommerce_retail_update = ecommerce_retail_update[ecommerce_retail_update['Quantity'] > 0]
# Only accept orders with Unit price >0
ecommerce_retail_update = ecommerce_retail_update[ecommerce_retail_update['UnitPrice'] > 0]
# Only accept orders that are not canceled.
ecommerce_retail_update = ecommerce_retail_update[~ecommerce_retail_update['InvoiceNo'].str.startswith('C')]
ecommerce_retail_update.shape

"""## **1.4. Handling missing values**"""

# Check missing values
missing = {'volumn': ecommerce_retail_update.isna().sum(),
           'percent': ecommerce_retail_update.isna().sum()/ecommerce_retail_update.shape[0]}
missing_df = pd.DataFrame(missing)
missing_df

# Check the missing CustomerID entries to determine the reason.
ecommerce_retail_update[ecommerce_retail_update['CustomerID'].isna()]

# Create a month column for trend analysis of missing data
ecommerce_retail_update['day'] = ecommerce_retail_update['InvoiceDate'].dt.date
ecommerce_retail_update['month'] = ecommerce_retail_update['day'].apply(lambda x: str(x)[:-3])
ecommerce_retail_update

# Check the trend of missing data by month
ecommerce_retail_update[ecommerce_retail_update['CustomerID'].isna()]['month'].value_counts().sort_index()

"""Comment: There are missing values nearly every month, indicating a need to review the system for improvements."""

# Drop missing values in Customer ID column
ecommerce_retail_update = ecommerce_retail_update.dropna(subset=['CustomerID'])
ecommerce_retail_update.shape

"""## **1.5. Handling duplicates**"""

#Detect duplicates
duplicates_df= ecommerce_retail_update.duplicated(subset=['InvoiceNo','StockCode','InvoiceDate','CustomerID'])
print(ecommerce_retail_update[duplicates_df].shape)

#Inspect specific duplicate rows to detect the reasons.
ecommerce_retail_update[duplicates_df]

# Check specific duplicate order IDs.
ecommerce_retail_update[(ecommerce_retail_update['InvoiceNo'] == '536381') & (ecommerce_retail_update['StockCode'] == '71270')].head()

ecommerce_retail_update[(ecommerce_retail_update['InvoiceNo'] == '536409') & (ecommerce_retail_update['StockCode'] == '90199C')].head()

"""Comment: Duplicates may arise from system errors."""

#Drop duplicate
ecommerce_retail_update = ecommerce_retail_update.drop_duplicates(subset=['InvoiceNo','StockCode','InvoiceDate','CustomerID'], keep ='first')
ecommerce_retail_update.shape

"""# **PART 2. DATA PROCESSING**"""

# Create Recency - Frequency - Monetary variables
# Use the last day as a reference point
Lastday = ecommerce_retail_update['day'].max()
# Create a column to calculate cost for each order
ecommerce_retail_update['Cost'] = ecommerce_retail_update['Quantity'] * ecommerce_retail_update['UnitPrice']

# Calculate RFM metrics
rfm = ecommerce_retail_update.groupby('CustomerID').agg(
    Recency = ('day', lambda x: -(Lastday - x.max()).days), # The longer the number of days, the lower the Recency rank -> invert the sign
    Frequency = ('CustomerID', 'count'),
    Monetary = ('Cost', 'sum')).reset_index()
# Adjust data types
rfm['Frequency'] = rfm['Frequency'].astype('int')
rfm.dtypes

rfm.head()

"""After completing the calculation of the Recency - Frequency - Monetary variables, we will detect outliers and process them to ensure more accurate data."""

# Observe outliers in the Recency variable.
import seaborn as sns
sns.boxplot(rfm['Recency'])

# Observe outliers in the Frequency variable.
sns.boxplot(rfm['Frequency'])

# Observe outliers in the Monetary variable.
sns.boxplot(rfm['Monetary'])

# Drop outliers
rfm_drop_outliers = rfm[(rfm['Recency'] < rfm['Recency'].quantile(0.95)) & \
                    (rfm['Frequency'] < rfm['Frequency'].quantile(0.95)) & \
                    (rfm['Monetary'] < rfm['Monetary'].quantile(0.95))]
rfm_drop_outliers.shape

#rmf_drop_outliners
sns.boxplot(rfm_drop_outliers['Recency'])

sns.boxplot(rfm_drop_outliers['Frequency'])

sns.boxplot(rfm_drop_outliers['Monetary'])

# Using qcut to create R, M, F
rfm_drop_outliers['R'] = pd.qcut(rfm_drop_outliers['Recency'], 5, labels=range(1,6)).astype(str)
rfm_drop_outliers['F'] = pd.qcut(rfm_drop_outliers['Frequency'], 5, labels=range(1,6)).astype(str)
rfm_drop_outliers['M'] = pd.qcut(rfm_drop_outliers['Monetary'], 5, labels=range(1,6)).astype(str)
rfm_drop_outliers['RFM'] = rfm_drop_outliers['R'] + rfm_drop_outliers['F'] + rfm_drop_outliers['M']
rfm_drop_outliers.head()

# Load data mapping segmentation
segmentation = pd.read_csv('segmentation.csv')
segmentation.head()

segmentation['RFM Score']= segmentation['RFM Score'].astype('string').str.split(',')
segmentation = segmentation.explode('RFM Score').reset_index(drop=True)
segmentation['RFM Score'] = segmentation['RFM Score'].apply(lambda x: x.replace(' ',''))
segmentation.head()

# merge proper segmentation
final_rfm = rfm_drop_outliers.merge(segmentation, left_on='RFM', right_on='RFM Score', how='left')
final_rfm.head()

"""# **PART 3. VISUALIZATION**

Overall the distribution of the RFM Modelling

Distribution of RFM Modelling by time

Distribution of RFM Modelling by location

## **3.1. Overall the distribution of the RFM Modelling**
"""

# Overall the distribution of the RFM Modelling
# Create data
segment_usercnt = final_rfm[['Segment','CustomerID']].groupby(['Segment']).count().reset_index().rename(columns={'CustomerID':'user_cnt'})
segment_usercnt['volumn_percent'] = ((segment_usercnt['user_cnt']/segment_usercnt['user_cnt'].sum())*100).round(0)
segment_usercnt['Segment'] = segment_usercnt['Segment'] + ' ' + segment_usercnt['volumn_percent'].astype(str) + '%'
segment_usercnt

# create treemap
import matplotlib.pyplot as plt
!pip install squarify
import squarify

Custom_colors = ['#845ec2', '#ffc75f', '#d65db1', '#f9f871', '#ff6f91', '#2c73d2', '#ff9671', '#008e9b', '#008f7a', '#b39cd0', '#fbeaff']
squarify.plot(sizes=segment_usercnt['user_cnt'], label=segment_usercnt['Segment'],
              color=Custom_colors, alpha=0.8, text_kwargs={'fontsize': 8, 'weight': 'bold'})
plt.axis('off')
plt.title('Percentage of customers by RMF Segmentation')
plt.show()

#segment spending
segment_spending = final_rfm[['Segment','Monetary']].groupby(['Segment']).agg({'Monetary':'sum'}).reset_index()
segment_spending['monetary_percent'] = ((segment_spending['Monetary']/segment_spending['Monetary'].sum())*100).round(0)
segment_spending['Segment'] = segment_spending['Segment'] + ' ' + segment_spending['monetary_percent'].astype(str) + '%'
squarify.plot(sizes=segment_spending['Monetary'], label=segment_spending['Segment'],
              color=Custom_colors, alpha=0.8, text_kwargs={'fontsize': 8, 'weight': 'bold'})
plt.axis('off')
plt.title('Percentage of customer spending by RMF Segmentation')
plt.show()

"""## **3.2. Distribution of RFM Modelling by time**
The time is the date customers entered the products
"""

# distribution of segment by time
rmf_customer_month = pd.merge(final_rfm, ecommerce_retail_update[['CustomerID','month']], on='CustomerID', how='left')
rmf_customer_month = rmf_customer_month.groupby(['month','Segment']).agg({'CustomerID':'count'}).reset_index().rename(columns={'CustomerID':'user_cnt'})
rmf_customer_month = rmf_customer_month.pivot_table(values='user_cnt', index='month', columns='Segment', fill_value =0)
rmf_customer_month = rmf_customer_month.div(rmf_customer_month.sum(axis=1), axis=0) * 100

Custom_colors = ['#845ec2', '#ffc75f', '#d65db1', '#f9f871', '#ff6f91', '#2c73d2', '#ff9671', '#008e9b', '#008f7a', '#b39cd0', '#fbeaff']
ax = rmf_customer_month.plot(kind='bar', stacked=True, color=Custom_colors)
plt.xticks(rotation=90)  # Rotate x-axis labels for better readability
plt.tight_layout() # Adjust layout to prevent overlapping
ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small', ncol=2)
plt.title('Percentage of customers by RMF Segmentation and time')
plt.show()

# distribution of segment monetary by time
rmf_monetary_month = pd.merge(final_rfm, ecommerce_retail_update[['CustomerID','month']], on='CustomerID', how='left')
rmf_monetary_month = rmf_monetary_month.groupby(['month','Segment']).agg({'Monetary':'sum'}).reset_index()
rmf_monetary_month = rmf_monetary_month.pivot_table(values='Monetary', index='month', columns='Segment', fill_value =0)
rmf_monetary_month = rmf_monetary_month.div(rmf_monetary_month.sum(axis=1), axis=0) * 100

ax = rmf_monetary_month.plot(kind='bar', stacked=True, color=Custom_colors)
plt.xticks(rotation=90)  # Rotate x-axis labels for better readability
plt.tight_layout() # Adjust layout to prevent overlapping
ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small', ncol=2)
plt.title('Percentage of customer spending by RMF Segmentation and time')
plt.show()

"""## **3.3. Distribution of RFM Modelling by location**"""

# distribution of segment by location
rmf_customer_country = pd.merge(final_rfm, ecommerce_retail_update[['CustomerID','Country']], on='CustomerID', how='left')
rmf_customer_country = rmf_customer_country.groupby(['Country','Segment']).agg({'CustomerID':'count'}).reset_index().rename(columns={'CustomerID':'user_cnt'})
rmf_customer_country = rmf_customer_country.pivot_table(values='user_cnt', index='Country', columns='Segment', fill_value =0)

Custom_colors = ['#845ec2', '#ffc75f', '#d65db1', '#f9f871', '#ff6f91', '#2c73d2', '#ff9671', '#008e9b', '#008f7a', '#b39cd0', '#fbeaff']
ax = rmf_customer_country.plot(kind='bar', stacked=True, color=Custom_colors)
plt.xticks(rotation=90)  # Rotate x-axis labels for better readability
plt.tight_layout() # Adjust layout to prevent overlapping
ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small', ncol=2)
plt.title('Percentage of customers by RMF Segmentation and location')
plt.show()

# distribution of segment monetary by location
rmf_monetary_country = pd.merge(final_rfm, ecommerce_retail_update[['CustomerID','Country']], on='CustomerID', how='left')
rmf_monetary_country = rmf_monetary_country.groupby(['Country','Segment']).agg({'Monetary':'sum'}).reset_index()
rmf_monetary_country = rmf_monetary_country.pivot_table(values='Monetary', index='Country', columns='Segment', fill_value =0)

Custom_colors = ['#845ec2', '#ffc75f', '#d65db1', '#f9f871', '#ff6f91', '#2c73d2', '#ff9671', '#008e9b', '#008f7a', '#b39cd0', '#fbeaff']
ax = rmf_monetary_country.plot(kind='bar', stacked=True, color=Custom_colors)
plt.xticks(rotation=90)  # Rotate x-axis labels for better readability
plt.tight_layout() # Adjust layout to prevent overlapping
ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small', ncol=2)
plt.title('Percentage of customer spending by RMF Segmentatio and location')
plt.show()